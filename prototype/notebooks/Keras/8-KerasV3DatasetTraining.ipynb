{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "assert len(keras.backend.tensorflow_backend._get_available_gpus()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000000, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs = pd.read_csv(\"~/code/fifteen-puzzle/data/datasets/15-costs-v3.csv\")\n",
    "costs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1   2  3   4   5   6   7   8   9  10  11  12  13  14  15  cost\n",
       "0  10  1   5  4  14  11  15   7   0   9   3   2   6   8  12  13    48\n",
       "1   1  7  12  2   5   0   6   3   9   8  14   4  13  11  10  15    26\n",
       "2   6  9   4  1  13   0  12  10   7   5  11  14   3  15   8   2    54\n",
       "3  15  5   0  6   9   4   8  11  10  13   2   1  12   3  14   7    54\n",
       "4   6  7  12  4   0  15  11   3  13  10   1   5   9  14   8   2    53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 382
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs.sample(10000).cost.hist(bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = costs.iloc[:,:-1].values\n",
    "y = costs['cost'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.apply_along_axis(lambda x: np.eye(16)[x].ravel(), 1, X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(layer_sizes, \n",
    "              learning_rate=0.001, \n",
    "              dropout_ratio=0.2, \n",
    "              activation='elu', \n",
    "              loss='mean_squared_error',\n",
    "              kernel_initializer='he_normal', \n",
    "              batch_normalize=True,\n",
    "              kernel_regularizer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], \n",
    "                    input_shape=(256,), \n",
    "                    activation=activation, \n",
    "                    kernel_initializer=kernel_initializer,\n",
    "                    kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Activation(activation))\n",
    "    if batch_normalize:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    \n",
    "    for layer_size in layer_sizes[1:]:\n",
    "        model.add(Dense(layer_size, \n",
    "                        activation=activation, \n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer))\n",
    "        model.add(Activation(activation))\n",
    "        if batch_normalize:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_ratio))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer='he_normal', kernel_regularizer=kernel_regularizer))\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=Adam(lr=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 25.3823 - val_loss: 7.7419\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.1440 - val_loss: 7.4210\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0567 - val_loss: 7.5353\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0554 - val_loss: 7.2117\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0418 - val_loss: 7.3295\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0284 - val_loss: 7.4610\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0202 - val_loss: 7.2063\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0251 - val_loss: 7.5841\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0223 - val_loss: 7.1752\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0152 - val_loss: 7.3301\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0065 - val_loss: 7.2914\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9894 - val_loss: 7.2436\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9938 - val_loss: 7.3479\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0070 - val_loss: 7.3197\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0166 - val_loss: 7.3940\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9919 - val_loss: 7.2409\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9864 - val_loss: 7.2578\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9789 - val_loss: 7.1333\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9682 - val_loss: 7.6808\n",
      "Epoch 20/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9502 - val_loss: 7.2616\n",
      "Epoch 21/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9585 - val_loss: 7.4432\n",
      "Epoch 22/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9656 - val_loss: 7.1142\n",
      "Epoch 23/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9820 - val_loss: 7.2610\n",
      "Epoch 24/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9635 - val_loss: 7.3025\n",
      "Epoch 25/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9740 - val_loss: 7.1299\n",
      "Epoch 26/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9694 - val_loss: 7.7850\n",
      "Epoch 27/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9649 - val_loss: 7.2232\n",
      "Epoch 28/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9712 - val_loss: 7.1565\n",
      "Epoch 29/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9703 - val_loss: 7.2295\n",
      "Epoch 30/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9555 - val_loss: 7.1985\n",
      "Epoch 31/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9583 - val_loss: 7.2079\n",
      "Epoch 32/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9555 - val_loss: 7.2363\n",
      "Epoch 33/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9760 - val_loss: 7.2783\n",
      "Epoch 34/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9762 - val_loss: 7.1968\n",
      "Epoch 35/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9825 - val_loss: 7.2264\n",
      "Epoch 36/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9528 - val_loss: 7.4862\n",
      "Epoch 37/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9654 - val_loss: 7.0959\n",
      "Epoch 38/100\n",
      "2443776/4800000 [==============>...............] - ETA: 26s - loss: 11.9680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a0c02fa37045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([15], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 8.0008 - val_loss: 3.1309\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 5.4179 - val_loss: 2.9020\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 5.0405 - val_loss: 4.2036\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.7940 - val_loss: 2.6208\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.6407 - val_loss: 2.7119\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.4608 - val_loss: 2.9327\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.3300 - val_loss: 2.5436\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 4.2245 - val_loss: 2.9734\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 4.1742 - val_loss: 2.6520\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.1200 - val_loss: 2.8819\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0988 - val_loss: 2.8884\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0841 - val_loss: 2.8396\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0741 - val_loss: 2.6604\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 4.0438 - val_loss: 2.9562\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0309 - val_loss: 2.6686\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0231 - val_loss: 2.8579\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0201 - val_loss: 2.9836\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0299 - val_loss: 2.9325\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0087 - val_loss: 2.5746\n",
      "Epoch 20/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0139 - val_loss: 2.5624\n",
      "Epoch 21/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 3.9999 - val_loss: 4.7259\n",
      "Epoch 22/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0244 - val_loss: 3.0595\n",
      "Epoch 23/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 3.9924 - val_loss: 2.5325\n",
      "Epoch 24/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 3.9811 - val_loss: 2.6233\n",
      "Epoch 25/100\n",
      "2217984/4800000 [============>.................] - ETA: 29s - loss: 3.9880"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e6938e73e367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([500], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 13.3002 - val_loss: 4.0712\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 7.8001 - val_loss: 4.6459\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.8031 - val_loss: 3.5528\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.4332 - val_loss: 4.2553\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.2579 - val_loss: 4.0340\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.1847 - val_loss: 3.9218\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.1346 - val_loss: 3.5830\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 142s 30us/sample - loss: 6.0986 - val_loss: 3.6551\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.0579 - val_loss: 3.6091\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.0319 - val_loss: 3.4777\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9899 - val_loss: 3.6145\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 142s 30us/sample - loss: 5.9883 - val_loss: 3.5197\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 142s 30us/sample - loss: 5.9556 - val_loss: 3.4196\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9598 - val_loss: 3.4947\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9243 - val_loss: 3.4008\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9189 - val_loss: 3.3627\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.8977 - val_loss: 3.3087\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.8779 - val_loss: 3.5730\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.8731 - val_loss: 3.5771\n",
      "Epoch 20/100\n",
      "4611584/4800000 [===========================>..] - ETA: 5s - loss: 5.8635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ff2059a22792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([100, 100, 100, 100, 100], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 67s 14us/sample - loss: 202.4892 - val_loss: 13.4314\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 66s 14us/sample - loss: 115237.4813 - val_loss: 164.7734\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 66s 14us/sample - loss: 167.3936 - val_loss: 164.8833\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 66s 14us/sample - loss: 549129.0161 - val_loss: 175.0603\n",
      "Epoch 5/100\n",
      " 420864/4800000 [=>............................] - ETA: 54s - loss: 18380.3153"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-96bb44167356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    894\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0munwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0munwrapped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36munwrapped\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeakObjectIdentityWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0munwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([100, 100, 100, 100, 100], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  batch_normalize=False)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 12.8883 - val_loss: 3.5692\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 5.7667 - val_loss: 2.5786\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 4.7603 - val_loss: 3.1555\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 4.4252 - val_loss: 309.1072\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.2636 - val_loss: 2.2508\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.1511 - val_loss: 4436.3405\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.0706 - val_loss: 14.5775\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.0452 - val_loss: 32.9513\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 4.0056 - val_loss: 19.9872\n",
      "Epoch 10/100\n",
      "4168448/4800000 [=========================>....] - ETA: 19s - loss: 3.9490"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c4fa3c66a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 7.3008 - val_loss: 2.8402\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 5.1486 - val_loss: 3.7827\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.8529 - val_loss: 4.8270\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.6608 - val_loss: 2.5731\n",
      "Epoch 5/100\n",
      "2498304/4800000 [==============>...............] - ETA: 39s - loss: 4.6195"
     ]
    }
   ],
   "source": [
    "model = get_model([5000], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 224s 47us/sample - loss: 48.8194 - val_loss: 11.4369\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 26.1217 - val_loss: 10.8959\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 218s 45us/sample - loss: 26.0487 - val_loss: 10.8269\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 222s 46us/sample - loss: 26.0719 - val_loss: 12.0236\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 217s 45us/sample - loss: 26.0500 - val_loss: 13.3661\n",
      "Epoch 6/100\n",
      "1746688/4800000 [=========>....................] - ETA: 2:03 - loss: 26.0422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38916d307d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([5, 5, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 172s 36us/sample - loss: 42.9939 - val_loss: 10.0021\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 174s 36us/sample - loss: 20.1647 - val_loss: 9.8603\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 164s 34us/sample - loss: 20.0829 - val_loss: 9.4635\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 161s 34us/sample - loss: 20.0729 - val_loss: 9.8240\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 166s 35us/sample - loss: 20.0878 - val_loss: 9.8719\n",
      "Epoch 6/100\n",
      " 790784/4800000 [===>..........................] - ETA: 2:01 - loss: 20.0811"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7676d89de169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# Callbacks batch end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    241\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3500\u001b[0m     \"\"\"\n\u001b[1;32m   3501\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3502\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3406\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3408\u001b[0;31m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3410\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([10, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/10\n",
      "4800000/4800000 [==============================] - 80s 17us/sample - loss: 25.5611 - val_loss: 7.3653\n",
      "Epoch 2/10\n",
      "4800000/4800000 [==============================] - 77s 16us/sample - loss: 12.0984 - val_loss: 7.0932\n",
      "Epoch 3/10\n",
      "4800000/4800000 [==============================] - 84s 17us/sample - loss: 12.0196 - val_loss: 7.1279\n",
      "Epoch 4/10\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 12.0069 - val_loss: 7.0612\n",
      "Epoch 5/10\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 11.9833 - val_loss: 6.9703\n",
      "Epoch 6/10\n",
      "4800000/4800000 [==============================] - 81s 17us/sample - loss: 11.9750 - val_loss: 7.1786\n",
      "Epoch 7/10\n",
      "4800000/4800000 [==============================] - 80s 17us/sample - loss: 11.9748 - val_loss: 6.9613\n",
      "Epoch 8/10\n",
      "4800000/4800000 [==============================] - 81s 17us/sample - loss: 11.9580 - val_loss: 6.9539\n",
      "Epoch 9/10\n",
      "4800000/4800000 [==============================] - 80s 17us/sample - loss: 11.9463 - val_loss: 7.0008\n",
      "Epoch 10/10\n",
      "4800000/4800000 [==============================] - 75s 16us/sample - loss: 11.9471 - val_loss: 6.9249\n"
     ]
    }
   ],
   "source": [
    "model = get_model([15], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  activation='relu')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 50.3523 - val_loss: 12.7424\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 130s 27us/sample - loss: 27.8034 - val_loss: 12.1463\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 131s 27us/sample - loss: 27.6975 - val_loss: 11.7970\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 128s 27us/sample - loss: 27.6322 - val_loss: 13.3223\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 134s 28us/sample - loss: 27.6775 - val_loss: 13.1721\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 137s 29us/sample - loss: 27.6419 - val_loss: 12.4129\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 137s 29us/sample - loss: 27.6025 - val_loss: 12.2265\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 147s 31us/sample - loss: 27.6078 - val_loss: 12.4064\n"
     ]
    }
   ],
   "source": [
    "model = get_model([5, 5, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  activation='relu')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 117s 24us/sample - loss: 42.3217 - val_loss: 8.3668\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 100s 21us/sample - loss: 18.9661 - val_loss: 8.1182\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 86s 18us/sample - loss: 18.8520 - val_loss: 7.6443\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 18.8636 - val_loss: 8.0244\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 84s 17us/sample - loss: 18.8398 - val_loss: 8.7172\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 18.8393 - val_loss: 8.2132\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 18.8204 - val_loss: 7.3794\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 84s 17us/sample - loss: 18.8080 - val_loss: 7.7428\n"
     ]
    }
   ],
   "source": [
    "model = get_model([15, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  activation='relu')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 11.1837 - val_loss: 3.7003\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 63s 13us/sample - loss: 6.8007 - val_loss: 3.6081\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 6.0367 - val_loss: 4.1625\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 5.6892 - val_loss: 3.4377\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 63s 13us/sample - loss: 5.5148 - val_loss: 3.6943\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 5.4518 - val_loss: 3.2989\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 5.4245 - val_loss: 3.3145\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 63s 13us/sample - loss: 5.3908 - val_loss: 3.2829\n"
     ]
    }
   ],
   "source": [
    "model = get_model([128], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/12\n",
      "4800000/4800000 [==============================] - 86s 18us/sample - loss: 21.9059 - val_loss: 4.0473\n",
      "Epoch 2/12\n",
      "4800000/4800000 [==============================] - 85s 18us/sample - loss: 8.2692 - val_loss: 3.7120\n",
      "Epoch 3/12\n",
      "4800000/4800000 [==============================] - 85s 18us/sample - loss: 8.0695 - val_loss: 3.5602\n",
      "Epoch 4/12\n",
      "4800000/4800000 [==============================] - 88s 18us/sample - loss: 7.9730 - val_loss: 4.1879\n",
      "Epoch 5/12\n",
      "4800000/4800000 [==============================] - 96s 20us/sample - loss: 7.9305 - val_loss: 3.3472\n",
      "Epoch 6/12\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 7.8957 - val_loss: 3.3317\n",
      "Epoch 7/12\n",
      "4800000/4800000 [==============================] - 96s 20us/sample - loss: 7.8690 - val_loss: 3.4243\n",
      "Epoch 8/12\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 7.8472 - val_loss: 3.8116\n",
      "Epoch 9/12\n",
      "4800000/4800000 [==============================] - 114s 24us/sample - loss: 7.8291 - val_loss: 3.9032\n",
      "Epoch 10/12\n",
      "4800000/4800000 [==============================] - 111s 23us/sample - loss: 7.8051 - val_loss: 3.2297\n",
      "Epoch 11/12\n",
      "4800000/4800000 [==============================] - 110s 23us/sample - loss: 7.7890 - val_loss: 3.8438\n",
      "Epoch 12/12\n",
      "4800000/4800000 [==============================] - 106s 22us/sample - loss: 7.7757 - val_loss: 3.2775\n"
     ]
    }
   ],
   "source": [
    "model = get_model([128, 16], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=12,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 136s 28us/sample - loss: 29.9069 - val_loss: 4.2152\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 136s 28us/sample - loss: 11.4651 - val_loss: 3.8083\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 11.2788 - val_loss: 4.0260\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 138s 29us/sample - loss: 11.1688 - val_loss: 4.3138\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 136s 28us/sample - loss: 11.0813 - val_loss: 4.0562\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 11.0176 - val_loss: 3.7826\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 137s 28us/sample - loss: 10.9728 - val_loss: 3.9522\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 10.9442 - val_loss: 3.8960\n"
     ]
    }
   ],
   "source": [
    "model = get_model([128, 32, 8], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 108s 23us/sample - loss: 7.1860 - val_loss: 3.3847\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 5.1986 - val_loss: 3.3246\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.8692 - val_loss: 4.8711\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.7152 - val_loss: 2.5231\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 108s 23us/sample - loss: 4.5298 - val_loss: 3.2547\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.4617 - val_loss: 2.7942\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.3447 - val_loss: 2.5366\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.2427 - val_loss: 2.3994\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.1448 - val_loss: 3.3732\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.0818 - val_loss: 2.9512\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.0262 - val_loss: 2.3891\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 3.9779 - val_loss: 2.5769\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 106s 22us/sample - loss: 3.9445 - val_loss: 2.9509\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.9523 - val_loss: 2.4075\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 106s 22us/sample - loss: 3.9162 - val_loss: 2.4417\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.9470 - val_loss: 2.4907\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.9263 - val_loss: 3.5233\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 3.8758 - val_loss: 2.4139\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.8645 - val_loss: 2.8473\n",
      "Epoch 20/100\n",
      " 402944/4800000 [=>............................] - ETA: 1:29 - loss: 3.8708"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-27dcb525a5ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([5000], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 13.0878 - val_loss: 2.9907\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 5.8280 - val_loss: 2.5856\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 4.7800 - val_loss: 2.7688\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 4.4607 - val_loss: 2.3796\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 4.3031 - val_loss: 15.3050\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.2039 - val_loss: 2.2770\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.1206 - val_loss: 8.9059\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 4.0869 - val_loss: 280505539.8805\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0325 - val_loss: 1052.1793\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9876 - val_loss: 5.5977\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.9669 - val_loss: 4.0471\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9446 - val_loss: 2.1333\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9237 - val_loss: 2.0119\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9024 - val_loss: 2.4977\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8632 - val_loss: 1.9823\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8550 - val_loss: 1.9337\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8300 - val_loss: 1.9897\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8304 - val_loss: 2.1272\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8079 - val_loss: 2.0409\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.7801 - val_loss: 2.0700\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 212s 44us/sample - loss: 12.9860 - val_loss: 3.1617\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 5.8028 - val_loss: 2.6816\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.7634 - val_loss: 2.5463\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.4010 - val_loss: 2.9659\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.2706 - val_loss: 2.1884\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.1639 - val_loss: 2.1545\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0972 - val_loss: 2.1666\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0556 - val_loss: 2.1983\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0265 - val_loss: 2.8349\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9863 - val_loss: 2.4432\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9457 - val_loss: 2.1738\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9340 - val_loss: 2.2053\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.9156 - val_loss: 2.0885\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8839 - val_loss: 2.0635\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8690 - val_loss: 8.3698\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8546 - val_loss: 2.0075\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8375 - val_loss: 2.1485\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8230 - val_loss: 2.1459\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 3.8196 - val_loss: 2.0498\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8136 - val_loss: 2.2360\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 223s 47us/sample - loss: 12.8854 - val_loss: 3.5177\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 229s 48us/sample - loss: 5.7637 - val_loss: 3.3164\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 246s 51us/sample - loss: 4.7659 - val_loss: 29.1539\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.4171 - val_loss: 2.4747\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.2490 - val_loss: 3.2411\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.1509 - val_loss: 2.5327\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.1054 - val_loss: 3.0509\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.0573 - val_loss: 5.4738\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.0072 - val_loss: 2.2892\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 3.9792 - val_loss: 2.3805\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.9524 - val_loss: 2.6415\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.9188 - val_loss: 2.2294\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 233s 48us/sample - loss: 3.8881 - val_loss: 1.9912\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8796 - val_loss: 2.0057\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8563 - val_loss: 1.9987\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8369 - val_loss: 2.0174\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.7997 - val_loss: 2.1469\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.7955 - val_loss: 1.9409\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8064 - val_loss: 2.1279\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.7880 - val_loss: 1.8837\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMSE, alpha=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_mean_squared_error_04(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true) * K.square(K.sign(y_pred - y_true) + 0.4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 247s 51us/sample - loss: 8.3800 - val_loss: 2.6513\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 242s 51us/sample - loss: 4.5051 - val_loss: 2.5057\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 242s 51us/sample - loss: 3.7943 - val_loss: 2.0409\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.5439 - val_loss: 1.9140\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.3845 - val_loss: 1.8999\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.3091 - val_loss: 2.4136\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.2403 - val_loss: 1.7266\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.2016 - val_loss: 1.8663\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.1717 - val_loss: 2.0870\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1603 - val_loss: 1.8342\n",
      "CPU times: user 56min 35s, sys: 4min 36s, total: 1h 1min 12s\n",
      "Wall time: 40min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-amse04-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 8.3634 - val_loss: 3.5793\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 253s 53us/sample - loss: 4.5414 - val_loss: 2.7090\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.8168 - val_loss: 2.3052\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.5222 - val_loss: 2.3101\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.3929 - val_loss: 1.8131\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.3102 - val_loss: 2.2506\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.2417 - val_loss: 1.8867\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.2142 - val_loss: 2.6003\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 245s 51us/sample - loss: 3.1755 - val_loss: 1.7152\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.1425 - val_loss: 1.9231\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.1303 - val_loss: 277.6915\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.1005 - val_loss: 88.0225\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0920 - val_loss: 1.7814\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0707 - val_loss: 914.4154\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0526 - val_loss: 1.8667\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0387 - val_loss: 1.9346\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0233 - val_loss: 62047076.8117\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.0152 - val_loss: 1.6986\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.0234 - val_loss: 1.7852\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.9836 - val_loss: 1.6347\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9867 - val_loss: 1.6535\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9805 - val_loss: 1.6567\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.9640 - val_loss: 356184.7334\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9588 - val_loss: 1.6762\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9552 - val_loss: 6457714.6806\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9433 - val_loss: 15661375.7751\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9330 - val_loss: 6195131.3061\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9262 - val_loss: 5113962.6409\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9131 - val_loss: 1.5780\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9230 - val_loss: 4999898.5668\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.9096 - val_loss: 3492335.0001\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8957 - val_loss: 137561.1607\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8920 - val_loss: 6884356.2422\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8941 - val_loss: 1475141.1350\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8860 - val_loss: 59552.7642\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8835 - val_loss: 234715.0152\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8852 - val_loss: 15694963.9812\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.8684 - val_loss: 4542683.9539\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8765 - val_loss: 1629458.8849\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8732 - val_loss: 3231357.1123\n",
      "CPU times: user 3h 41min 36s, sys: 18min 32s, total: 4h 9s\n",
      "Wall time: 2h 39min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-amse04-3.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 8.3150 - val_loss: 2.4547\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 4.4960 - val_loss: 2.7192\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 3.7889 - val_loss: 2.4314\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.5379 - val_loss: 1.9856\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.3963 - val_loss: 48.4876\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.3032 - val_loss: 2.8606\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 238s 49us/sample - loss: 3.2540 - val_loss: 4.5467\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.2179 - val_loss: 4.7233\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.1747 - val_loss: 4.0300\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.1527 - val_loss: 1.8894\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 238s 49us/sample - loss: 3.1312 - val_loss: 1.8136\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.1104 - val_loss: 1.8657\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0980 - val_loss: 1.7585\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0770 - val_loss: 1.7649\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 3.0519 - val_loss: 1.6816\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0295 - val_loss: 1.8498\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0239 - val_loss: 1.7714\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0147 - val_loss: 1.7429\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0045 - val_loss: 1.8313\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9977 - val_loss: 1.6902\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9931 - val_loss: 1.9906\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9869 - val_loss: 1.8978\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9728 - val_loss: 1.6030\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.9637 - val_loss: 1.8370\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9568 - val_loss: 1.6377\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9515 - val_loss: 1.7680\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9436 - val_loss: 1.6250\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9243 - val_loss: 1.6446\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.9224 - val_loss: 1.5389\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.9179 - val_loss: 1.6121\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9032 - val_loss: 1.7710\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9076 - val_loss: 1.5725\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8994 - val_loss: 1.6273\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8949 - val_loss: 1.6577\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8737 - val_loss: 1.7294\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.8766 - val_loss: 1.5923\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8839 - val_loss: 1.8764\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.8782 - val_loss: 6.6154\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8624 - val_loss: 1.8187\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8611 - val_loss: 2.3418\n",
      "CPU times: user 3h 41min 46s, sys: 18min 33s, total: 4h 19s\n",
      "Wall time: 2h 38min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('keras-1024-1024-512-128-64-v3-amse04-3.h5',\n",
    "                                   custom_objects={asymmetric_mean_squared_error_04.__name__: asymmetric_mean_squared_error_04})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8913850946363677"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 8.3449 - val_loss: 3.7893\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 4.4897 - val_loss: 2.2052\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.7583 - val_loss: 2.0451\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.5055 - val_loss: 2.0100\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.3776 - val_loss: 2.0147\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.3018 - val_loss: 2.0523\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.2558 - val_loss: 1.8675\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.2037 - val_loss: 1.7872\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1923 - val_loss: 3.2376\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1583 - val_loss: 8.8307\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1185 - val_loss: 1216.3931\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0966 - val_loss: 1.9918\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.0890 - val_loss: 110930.8774\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0621 - val_loss: 156.8690\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0546 - val_loss: 6.5130\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.0455 - val_loss: 1.7364\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0286 - val_loss: 1.7845\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.0185 - val_loss: 1.7453\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0095 - val_loss: 1.6705\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9940 - val_loss: 2.1684\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9907 - val_loss: 1.9844\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 224s 47us/sample - loss: 2.9715 - val_loss: 1.5377\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9703 - val_loss: 1.6315\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 247s 51us/sample - loss: 2.9606 - val_loss: 2.3864\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 2.9516 - val_loss: 1.8395\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9390 - val_loss: 1.9771\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9424 - val_loss: 1.6930\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9275 - val_loss: 1.6061\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9287 - val_loss: 1.9347\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9238 - val_loss: 1.6880\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9131 - val_loss: 1.5577\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9100 - val_loss: 1.7984\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8974 - val_loss: 1.8434\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.8991 - val_loss: 1.8684\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8944 - val_loss: 1.8435\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8924 - val_loss: 1.5575\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8934 - val_loss: 94.0635\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8824 - val_loss: 13.4017\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.8819 - val_loss: 1.6585\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.8684 - val_loss: 267093.3174\n",
      "CPU times: user 3h 40min 45s, sys: 18min 4s, total: 3h 58min 49s\n",
      "Wall time: 2h 41min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 8.3486 - val_loss: 4.7409\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 4.5064 - val_loss: 2.1276\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.7776 - val_loss: 2.2662\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.5308 - val_loss: 2.6638\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.4002 - val_loss: 1.9170\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.3178 - val_loss: 2.6013\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.2558 - val_loss: 1.7402\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 3.2282 - val_loss: 10791.7317\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 3.1876 - val_loss: 1437.1145\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.1708 - val_loss: 469.4790\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.1319 - val_loss: 139960.6894\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.1044 - val_loss: 4579060.3049\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0858 - val_loss: 5329438.3289\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.0830 - val_loss: 18408214.2301\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0594 - val_loss: 31789944.5470\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.0419 - val_loss: 162245988.1828\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0339 - val_loss: 88622506.1740\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 252s 53us/sample - loss: 3.0268 - val_loss: 585828.9373\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0187 - val_loss: 4911885.5310\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9969 - val_loss: 58244169.3112\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9935 - val_loss: 367343743.9879\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9808 - val_loss: 364841271.1517\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9775 - val_loss: 792687609.1806\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9676 - val_loss: 6443006.5615\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9474 - val_loss: 385887654.6068\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 2.9482 - val_loss: 48253160.6182\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9462 - val_loss: 142375366.3380\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9345 - val_loss: 112080.9123\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 2.9242 - val_loss: 1563385346.9028\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9265 - val_loss: 147921938.0516\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9264 - val_loss: 296702082.2584\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 2.9185 - val_loss: 6566833.6883\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 258s 54us/sample - loss: 2.9017 - val_loss: 58608063.5017\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 253s 53us/sample - loss: 2.9080 - val_loss: 206219016.5040\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 252s 53us/sample - loss: 2.8881 - val_loss: 45578219.3036\n",
      "Epoch 36/40\n",
      "1070336/4800000 [=====>........................] - ETA: 3:01 - loss: 2.8753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-5.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 270s 56us/sample - loss: 13.0070 - val_loss: 3.3146\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 5.7860 - val_loss: 4.5887\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.7713 - val_loss: 2.5165\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.4423 - val_loss: 2.5784\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 258s 54us/sample - loss: 4.3127 - val_loss: 2.2928\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.1951 - val_loss: 12.5933\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.1247 - val_loss: 2.5574\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0545 - val_loss: 2.9832\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0182 - val_loss: 2.3749\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.9742 - val_loss: 163.8348\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9571 - val_loss: 2.2052\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 257s 54us/sample - loss: 3.9274 - val_loss: 2.1400\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9101 - val_loss: 2.1041\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8916 - val_loss: 2.1763\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 257s 53us/sample - loss: 3.8878 - val_loss: 2.3184\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8442 - val_loss: 2.0434\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8313 - val_loss: 2.1751\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8212 - val_loss: 2.3354\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8035 - val_loss: 1.9400\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7991 - val_loss: 1.9030\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7657 - val_loss: 1.9228\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7759 - val_loss: 2.4104\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7576 - val_loss: 1.9955\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7567 - val_loss: 2.0136\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7399 - val_loss: 1.9386\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7368 - val_loss: 1.9805\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 257s 53us/sample - loss: 3.7158 - val_loss: 2.1287\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7139 - val_loss: 1.8709\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.7070 - val_loss: 2.1099\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.7209 - val_loss: 1.8675\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6997 - val_loss: 2.2452\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6951 - val_loss: 2.4613\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6976 - val_loss: 1.8948\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6837 - val_loss: 1.9712\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6727 - val_loss: 2.0730\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 257s 53us/sample - loss: 3.6778 - val_loss: 1.9845\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6669 - val_loss: 2.0188\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6514 - val_loss: 2.4476\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6546 - val_loss: 1.9911\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6467 - val_loss: 2.3256\n",
      "CPU times: user 3h 53min 1s, sys: 19min 43s, total: 4h 12min 44s\n",
      "Wall time: 2h 50min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('keras-1024-1024-512-128-64-v3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8675305894823022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 271s 56us/sample - loss: 13.0124 - val_loss: 3.6991\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 5.7911 - val_loss: 3.7446\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.7769 - val_loss: 2.5686\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.4388 - val_loss: 2.3743\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.2847 - val_loss: 2.4757\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.1626 - val_loss: 2.1205\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.1088 - val_loss: 2.4977\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0771 - val_loss: 2.1508\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0196 - val_loss: 2.1536\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.9921 - val_loss: 2.4548\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9656 - val_loss: 2.1206\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9379 - val_loss: 2.2943\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 265s 55us/sample - loss: 3.9026 - val_loss: 2.1921\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.8971 - val_loss: 2.1851\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.8661 - val_loss: 1.9834\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 268s 56us/sample - loss: 3.8501 - val_loss: 2.0140\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 278s 58us/sample - loss: 3.8396 - val_loss: 2.1410\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 271s 57us/sample - loss: 3.8229 - val_loss: 2.1005\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 326s 68us/sample - loss: 3.8207 - val_loss: 1.9484\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 328s 68us/sample - loss: 3.8010 - val_loss: 1.9993\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 328s 68us/sample - loss: 3.7982 - val_loss: 2.0993\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 328s 68us/sample - loss: 3.7767 - val_loss: 1.9732\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 327s 68us/sample - loss: 3.7673 - val_loss: 2.0655\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 320s 67us/sample - loss: 3.7518 - val_loss: 2.2873\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 334s 70us/sample - loss: 3.7488 - val_loss: 1.8986\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 331s 69us/sample - loss: 3.7412 - val_loss: 1.9701\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 333s 69us/sample - loss: 3.7428 - val_loss: 1.9944\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 331s 69us/sample - loss: 3.7434 - val_loss: 1.9937\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 330s 69us/sample - loss: 3.7106 - val_loss: 1.9217\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 330s 69us/sample - loss: 3.7182 - val_loss: 2.3163\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 333s 69us/sample - loss: 3.7043 - val_loss: 2.1778\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 332s 69us/sample - loss: 3.7031 - val_loss: 2.0672\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 259s 54us/sample - loss: 3.6970 - val_loss: 2.0881\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6829 - val_loss: 1.9642\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6939 - val_loss: 2.2310\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 254s 53us/sample - loss: 3.6750 - val_loss: 2.3429\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6682 - val_loss: 2.4458\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6646 - val_loss: 76118.5880\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 254s 53us/sample - loss: 3.6570 - val_loss: 434056.1523\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6692 - val_loss: 1038544.6152\n",
      "CPU times: user 4h 16min 51s, sys: 18min 49s, total: 4h 35min 41s\n",
      "Wall time: 3h 8min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 277s 58us/sample - loss: 13.0028 - val_loss: 3.3558\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 5.8031 - val_loss: 2.6444\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.7973 - val_loss: 2.5292\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 261s 54us/sample - loss: 4.4799 - val_loss: 2.4988\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.3033 - val_loss: 808.3861\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.1995 - val_loss: 4.0642\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.1261 - val_loss: 220.3238\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.0780 - val_loss: 47311.7997\n",
      "Epoch 9/40\n",
      "4798976/4800000 [============================>.] - ETA: 0s - loss: 4.0697"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    483\u001b[0m   \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_input_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3867\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3868\u001b[0m     \"\"\"\n\u001b[0;32m-> 3869\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3871\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 281s 59us/sample - loss: 13.0054 - val_loss: 3.2030\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 5.7812 - val_loss: 2.7538\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 4.7179 - val_loss: 12.6293\n",
      "Epoch 4/40\n",
      "2884608/4800000 [=================>............] - ETA: 1:36 - loss: 4.4559"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/30\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 7.2334 - val_loss: 3.3782\n",
      "Epoch 2/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 5.1244 - val_loss: 3.0224\n",
      "Epoch 3/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.8281 - val_loss: 2.7550\n",
      "Epoch 4/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.6901 - val_loss: 4.2794\n",
      "Epoch 5/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.5216 - val_loss: 4.8058\n",
      "Epoch 6/30\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 4.4135 - val_loss: 3.0279\n",
      "Epoch 7/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.2783 - val_loss: 2.5983\n",
      "Epoch 8/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.1820 - val_loss: 2.3754\n",
      "Epoch 9/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.0460 - val_loss: 2.6025\n",
      "Epoch 10/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.0142 - val_loss: 3.8428\n",
      "Epoch 11/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.9608 - val_loss: 2.3549\n",
      "Epoch 12/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.9020 - val_loss: 2.9286\n",
      "Epoch 13/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 3.8773 - val_loss: 2.5941\n",
      "Epoch 14/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8752 - val_loss: 2.3389\n",
      "Epoch 15/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8479 - val_loss: 2.8763\n",
      "Epoch 16/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 3.8644 - val_loss: 2.3547\n",
      "Epoch 17/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8100 - val_loss: 2.6379\n",
      "Epoch 18/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8173 - val_loss: 2.4167\n",
      "Epoch 19/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8073 - val_loss: 2.6643\n",
      "Epoch 20/30\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 3.8172 - val_loss: 2.9329\n",
      "Epoch 21/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8072 - val_loss: 2.4161\n",
      "Epoch 22/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8245 - val_loss: 2.3694\n",
      "Epoch 23/30\n",
      "1272064/4800000 [======>.......................] - ETA: 1:01 - loss: 3.7915"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    894\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-2752-v3-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([2752], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../../../data/neural-networks/keras-2752-v3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.338850735974764"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMSE, alpha=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_mean_squared_error_08(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true) * K.square(K.sign(y_pred - y_true) + 0.8), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 227s 47us/sample - loss: 2.1133 - val_loss: 1.2484\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 220s 46us/sample - loss: 1.3495 - val_loss: 0.9024\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 220s 46us/sample - loss: 1.1535 - val_loss: 0.8088\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 1.0606 - val_loss: 0.8008\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 220s 46us/sample - loss: 1.0263 - val_loss: 158.7723\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 213s 44us/sample - loss: 1.0025 - val_loss: 9155.0816\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 211s 44us/sample - loss: 0.9738 - val_loss: 21441377.7994\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 0.9592 - val_loss: 169158.1780\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 0.9465 - val_loss: 46209.4053\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 213s 44us/sample - loss: 0.9374 - val_loss: 353401.8224\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 220s 46us/sample - loss: 0.9257 - val_loss: 136019553.5532\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 221s 46us/sample - loss: 0.9242 - val_loss: 107750.0396\n",
      "Epoch 13/40\n",
      "4395776/4800000 [==========================>...] - ETA: 17s - loss: 0.9136"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse08-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_08)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 2.1200 - val_loss: 0.8912\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 216s 45us/sample - loss: 1.3664 - val_loss: 0.8670\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 212s 44us/sample - loss: 1.1654 - val_loss: 0.7186\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 207s 43us/sample - loss: 1.0713 - val_loss: 0.7474\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 205s 43us/sample - loss: 1.0342 - val_loss: 0.7858\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 215s 45us/sample - loss: 1.0052 - val_loss: 0.8138\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 220s 46us/sample - loss: 0.9796 - val_loss: 0.6544\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 0.9619 - val_loss: 1035.0545\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 0.9531 - val_loss: 178553087.2363\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 218s 45us/sample - loss: 0.9433 - val_loss: 10.0701\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 218s 46us/sample - loss: 0.9300 - val_loss: 381187057.1057\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 218s 45us/sample - loss: 0.9260 - val_loss: 3.8359\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 215s 45us/sample - loss: 0.9151 - val_loss: 658.6999\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 214s 44us/sample - loss: 0.9153 - val_loss: 475843.9607\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 0.9068 - val_loss: 55806501432.1408\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 0.9022 - val_loss: 6355.7718\n",
      "Epoch 17/40\n",
      " 317184/4800000 [>.............................] - ETA: 3:15 - loss: 0.8786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse08-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_08)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.1254 - val_loss: 0.9044\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 233s 48us/sample - loss: 1.3596 - val_loss: 0.6986\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 1.1615 - val_loss: 0.9420\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 1.0720 - val_loss: 0.7254\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 232s 48us/sample - loss: 1.0335 - val_loss: 0.7487\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 232s 48us/sample - loss: 1.0089 - val_loss: 0.6441\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 222s 46us/sample - loss: 0.9807 - val_loss: 0.6975\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 220s 46us/sample - loss: 0.9628 - val_loss: 91495.7025\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 227s 47us/sample - loss: 0.9499 - val_loss: 110840.3582\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 0.9385 - val_loss: 0.9097\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 0.9299 - val_loss: 3164455.7286\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 233s 48us/sample - loss: 0.9170 - val_loss: 61272780.1039\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 232s 48us/sample - loss: 0.9141 - val_loss: 2062102.4688\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 233s 48us/sample - loss: 0.9050 - val_loss: 39020968.8733\n",
      "Epoch 15/40\n",
      " 841472/4800000 [====>.........................] - ETA: 2:57 - loss: 0.9006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse08-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_08)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-amse08-4.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.1227 - val_loss: 1.0662\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 224s 47us/sample - loss: 1.3615 - val_loss: 1.0638\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 1.1538 - val_loss: 0.9954\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 1.0707 - val_loss: 0.8823\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 1.0247 - val_loss: 1334.0007\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9961 - val_loss: 52.1198\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9730 - val_loss: 0.5880\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9605 - val_loss: 36201.0172\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 182s 38us/sample - loss: 0.9484 - val_loss: 190364.4569\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9393 - val_loss: 9309782.2663\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 182s 38us/sample - loss: 0.9275 - val_loss: 118751.5629\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9251 - val_loss: 4937550.8883\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9167 - val_loss: 2729040.2463\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9096 - val_loss: 58982.6392\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.9026 - val_loss: 269663056.4557\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.8980 - val_loss: 5151339.4444\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 182s 38us/sample - loss: 0.8974 - val_loss: 276744227.9397\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.8866 - val_loss: 6920773.6398\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.8896 - val_loss: 14765032.0242\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 182s 38us/sample - loss: 0.8845 - val_loss: 188509974.3661\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.8787 - val_loss: 605059985.9290\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 183s 38us/sample - loss: 0.8777 - val_loss: 114836929.9431\n",
      "Epoch 23/40\n",
      "3286016/4800000 [===================>..........] - ETA: 53s - loss: 0.8712"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse08-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_08)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 191s 40us/sample - loss: 2.1151 - val_loss: 1.1748\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 1.3585 - val_loss: 0.7465\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 184s 38us/sample - loss: 1.1602 - val_loss: 0.7429\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 185s 39us/sample - loss: 1.0658 - val_loss: 0.6872\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 1.0209 - val_loss: 0.8608\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.9931 - val_loss: 0.7329\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.9754 - val_loss: 145446.2285\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 185s 39us/sample - loss: 0.9645 - val_loss: 31156838.5349\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 184s 38us/sample - loss: 0.9468 - val_loss: 9047492.8561\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.9342 - val_loss: 102539847.6180\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.9299 - val_loss: 324938086.0279\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.9181 - val_loss: 1620245.6487\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 184s 38us/sample - loss: 0.9186 - val_loss: 1060267276.6093\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 184s 38us/sample - loss: 0.9064 - val_loss: 511781484.3202\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 184s 38us/sample - loss: 0.9024 - val_loss: 789512.9424\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.9013 - val_loss: 40305319.5710\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.8921 - val_loss: 13141208.3714\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.8877 - val_loss: 2764558.0611\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 184s 38us/sample - loss: 0.8851 - val_loss: 3214440528.8258\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 185s 38us/sample - loss: 0.8797 - val_loss: 1266692719.6420\n",
      "CPU times: user 1h 28min 32s, sys: 9min 21s, total: 1h 37min 53s\n",
      "Wall time: 1h 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse08-5.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_08)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMSE, alpha=0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_mean_squared_error_06(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true) * K.square(K.sign(y_pred - y_true) + 0.6), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 5.2491 - val_loss: 2.3108\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 3.0774 - val_loss: 1.5872\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.5939 - val_loss: 1.4959\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.4423 - val_loss: 1.3834\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.3579 - val_loss: 17.4230\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.2945 - val_loss: 51.7208\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.2252 - val_loss: 3306752.9258\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.1922 - val_loss: 11283135.7176\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.1585 - val_loss: 83999992.0237\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.1351 - val_loss: 302598263.7250\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.1236 - val_loss: 20880908.0414\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.1068 - val_loss: 16528409.0961\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.1001 - val_loss: 11918997.0332\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.0842 - val_loss: 36606434.4909\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.0640 - val_loss: 2400272943.2243\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 186s 39us/sample - loss: 2.0607 - val_loss: 2489.1572\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0492 - val_loss: 44141974432.1664\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0481 - val_loss: 1197700.6341\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0263 - val_loss: 1.3435\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0300 - val_loss: 1157104232.8192\n",
      "CPU times: user 1h 28min 59s, sys: 9min 11s, total: 1h 38min 11s\n",
      "Wall time: 1h 2min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse06-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_06)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-amse06-2.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 196s 41us/sample - loss: 5.2460 - val_loss: 3.0782\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 3.0804 - val_loss: 2.2901\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.6208 - val_loss: 1.5088\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.4576 - val_loss: 1.5083\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.3556 - val_loss: 1.4535\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.2868 - val_loss: 1.2265\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.2417 - val_loss: 1.4409\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.2112 - val_loss: 1.3712\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.1845 - val_loss: 1.2844\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.1607 - val_loss: 1.4878\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.1456 - val_loss: 1.4557\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.1228 - val_loss: 1.6819\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.1063 - val_loss: 1.1852\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.1013 - val_loss: 1.3631\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0923 - val_loss: 1.5382\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 188s 39us/sample - loss: 2.0657 - val_loss: 2.1892\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0594 - val_loss: 1.5229\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0539 - val_loss: 2.5429\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0576 - val_loss: 17.9467\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 187s 39us/sample - loss: 2.0372 - val_loss: 1.4796\n",
      "CPU times: user 1h 30min, sys: 9min 8s, total: 1h 39min 8s\n",
      "Wall time: 1h 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse06-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_06)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 5.2476 - val_loss: 1.6891\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 3.0715 - val_loss: 1.4836\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.6016 - val_loss: 1.4421\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.4405 - val_loss: 1.4363\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.3475 - val_loss: 1.4069\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.2703 - val_loss: 1.3585\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.2277 - val_loss: 1.4979\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.1851 - val_loss: 3.0871\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.1667 - val_loss: 1.3131\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.1401 - val_loss: 2224.3144\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.1139 - val_loss: 71077.6927\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.1119 - val_loss: 120.5311\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.0951 - val_loss: 215663.5847\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.0811 - val_loss: 133435.1659\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.0720 - val_loss: 200762.6953\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.0663 - val_loss: 70965924.0353\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.0557 - val_loss: 233339.2255\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.0426 - val_loss: 331813.9542\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 192s 40us/sample - loss: 2.0371 - val_loss: 115086.3288\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.0274 - val_loss: 297079.3902\n",
      "CPU times: user 1h 30min 17s, sys: 9min 38s, total: 1h 39min 56s\n",
      "Wall time: 1h 4min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse06-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_06)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 203s 42us/sample - loss: 5.2506 - val_loss: 2.0185\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 3.0868 - val_loss: 1.7826\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.6150 - val_loss: 17.5922\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.4281 - val_loss: 1.6462\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.3452 - val_loss: 207.7624\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.2713 - val_loss: 1.3969\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.2234 - val_loss: 1.4276\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.1911 - val_loss: 120.6433\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.1664 - val_loss: 1.6275\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.1392 - val_loss: 7230.7244\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.1171 - val_loss: 77285.1219\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.1109 - val_loss: 1.7697\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.0887 - val_loss: 8588700.5108\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.0883 - val_loss: 6570240795.3916\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.0660 - val_loss: 8709140126.9184\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.0626 - val_loss: 4874097552.2073\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.0525 - val_loss: 2337606832.1264\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.0439 - val_loss: 729310.7904\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 194s 40us/sample - loss: 2.0305 - val_loss: 180630382.6581\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 193s 40us/sample - loss: 2.0332 - val_loss: 284884358.3662\n",
      "CPU times: user 1h 31min 48s, sys: 9min 34s, total: 1h 41min 22s\n",
      "Wall time: 1h 4min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse06-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_06)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMSE, alpha=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_mean_squared_error_02(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true) * K.square(K.sign(y_pred - y_true) + 0.2), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-amse02-1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 207s 43us/sample - loss: 10.9473 - val_loss: 3.1921\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 5.3974 - val_loss: 2.6533\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 4.5112 - val_loss: 3.1052\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 4.2046 - val_loss: 3.3731\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 4.0467 - val_loss: 6.5214\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.9581 - val_loss: 2.4908\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.9028 - val_loss: 2.0573\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.8402 - val_loss: 2.4073\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.8028 - val_loss: 1.9727\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.7643 - val_loss: 5.2021\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.7577 - val_loss: 2.2343\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.7144 - val_loss: 4.1648\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6858 - val_loss: 2.2124\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6713 - val_loss: 2.5986\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6504 - val_loss: 73.4357\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6468 - val_loss: 2.9342\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6242 - val_loss: 4.2600\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6011 - val_loss: 2.9328\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.5888 - val_loss: 1.9672\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.5666 - val_loss: 1.8599\n",
      "CPU times: user 1h 32min 30s, sys: 9min 52s, total: 1h 42min 23s\n",
      "Wall time: 1h 6min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse02-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_02)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 11.0026 - val_loss: 2.8755\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 5.4186 - val_loss: 2.6749\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 4.5004 - val_loss: 2.2149\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 4.2224 - val_loss: 2.8609\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 4.0647 - val_loss: 2.1738\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.9593 - val_loss: 2.2174\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.8786 - val_loss: 2.1148\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.8385 - val_loss: 19.8248\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.8141 - val_loss: 2.0007\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.7666 - val_loss: 2.0814\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.7423 - val_loss: 2.0967\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.7191 - val_loss: 1.9162\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.6957 - val_loss: 228.8834\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.6694 - val_loss: 1.9396\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.6641 - val_loss: 21359.2783\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6312 - val_loss: 4.1467\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.6135 - val_loss: 2.2462\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.6123 - val_loss: 1.9554\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 198s 41us/sample - loss: 3.5926 - val_loss: 1.8611\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 197s 41us/sample - loss: 3.5811 - val_loss: 4323.6436\n",
      "CPU times: user 1h 34min 12s, sys: 9min 56s, total: 1h 44min 9s\n",
      "Wall time: 1h 6min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse02-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_02)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 212s 44us/sample - loss: 10.9628 - val_loss: 3.3947\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 5.4181 - val_loss: 3.8279\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 4.5051 - val_loss: 3.2095\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 4.2289 - val_loss: 2983.6754\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 4.0668 - val_loss: 819.4712\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.9630 - val_loss: 175533.7528\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.8872 - val_loss: 4.2976\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.8475 - val_loss: 222.8363\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.8036 - val_loss: 20.4528\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.7570 - val_loss: 2.2264\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.7512 - val_loss: 1.9575\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.7210 - val_loss: 1.9283\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.6949 - val_loss: 2.0110\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.6510 - val_loss: 3.0163\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.6514 - val_loss: 1.9320\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.6237 - val_loss: 2.0085\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.6257 - val_loss: 1.9232\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 202s 42us/sample - loss: 3.6039 - val_loss: 2.0462\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.5871 - val_loss: 2.5023\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 201s 42us/sample - loss: 3.5629 - val_loss: 1.8855\n",
      "CPU times: user 1h 33min 50s, sys: 9min 41s, total: 1h 43min 31s\n",
      "Wall time: 1h 7min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse02-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_02)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 211s 44us/sample - loss: 10.9276 - val_loss: 2.8893\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 5.4240 - val_loss: 2.5073\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 199s 41us/sample - loss: 4.5514 - val_loss: 10.2701\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 4.2415 - val_loss: 2.3053\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 4.0853 - val_loss: 2.3323\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 199s 41us/sample - loss: 3.9979 - val_loss: 242.8811\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.9088 - val_loss: 2.2526\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 199s 42us/sample - loss: 3.8597 - val_loss: 3.5503\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.8187 - val_loss: 2.3077\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 211s 44us/sample - loss: 3.7786 - val_loss: 199.4812\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 211s 44us/sample - loss: 3.7691 - val_loss: 2.1068\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.7297 - val_loss: 2.1654\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.7156 - val_loss: 3.0881\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.6829 - val_loss: 2.3742\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.6815 - val_loss: 1.9346\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 199s 42us/sample - loss: 3.6570 - val_loss: 2.1279\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 199s 42us/sample - loss: 3.6363 - val_loss: 5.4371\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 200s 42us/sample - loss: 3.6287 - val_loss: 1.8931\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 199s 41us/sample - loss: 3.6133 - val_loss: 242.7754\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 199s 42us/sample - loss: 3.6068 - val_loss: 6529.4795\n",
      "CPU times: user 1h 34min 23s, sys: 9min 11s, total: 1h 43min 34s\n",
      "Wall time: 1h 7min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse02-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_02)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
