{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "assert len(keras.backend.tensorflow_backend._get_available_gpus()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the ANNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000000, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs = pd.read_csv(\"~/code/fifteen-puzzle/data/datasets/15-costs-v3.csv\")\n",
    "costs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1   2  3   4   5   6   7   8   9  10  11  12  13  14  15  cost\n",
       "0  10  1   5  4  14  11  15   7   0   9   3   2   6   8  12  13    48\n",
       "1   1  7  12  2   5   0   6   3   9   8  14   4  13  11  10  15    26\n",
       "2   6  9   4  1  13   0  12  10   7   5  11  14   3  15   8   2    54\n",
       "3  15  5   0  6   9   4   8  11  10  13   2   1  12   3  14   7    54\n",
       "4   6  7  12  4   0  15  11   3  13  10   1   5   9  14   8   2    53"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 381
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "costs.sample(10000).cost.hist(bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = costs.iloc[:,:-1].values\n",
    "y = costs['cost'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.apply_along_axis(lambda x: np.eye(16)[x].ravel(), 1, X_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(layer_sizes, \n",
    "              learning_rate=0.001, \n",
    "              dropout_ratio=0.2, \n",
    "              activation='elu', \n",
    "              loss='mean_squared_error',\n",
    "              kernel_initializer='he_normal', \n",
    "              batch_normalize=True,\n",
    "              kernel_regularizer=None):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer_sizes[0], \n",
    "                    input_shape=(256,), \n",
    "                    activation=activation, \n",
    "                    kernel_initializer=kernel_initializer,\n",
    "                    kernel_regularizer=kernel_regularizer))\n",
    "    model.add(Activation(activation))\n",
    "    if batch_normalize:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_ratio))\n",
    "    \n",
    "    for layer_size in layer_sizes[1:]:\n",
    "        model.add(Dense(layer_size, \n",
    "                        activation=activation, \n",
    "                        kernel_initializer=kernel_initializer,\n",
    "                        kernel_regularizer=kernel_regularizer))\n",
    "        model.add(Activation(activation))\n",
    "        if batch_normalize:\n",
    "            model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout_ratio))\n",
    "\n",
    "    model.add(Dense(1, kernel_initializer='he_normal', kernel_regularizer=kernel_regularizer))\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=Adam(lr=learning_rate))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 25.3823 - val_loss: 7.7419\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.1440 - val_loss: 7.4210\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0567 - val_loss: 7.5353\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0554 - val_loss: 7.2117\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0418 - val_loss: 7.3295\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0284 - val_loss: 7.4610\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0202 - val_loss: 7.2063\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0251 - val_loss: 7.5841\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0223 - val_loss: 7.1752\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0152 - val_loss: 7.3301\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 12.0065 - val_loss: 7.2914\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9894 - val_loss: 7.2436\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9938 - val_loss: 7.3479\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0070 - val_loss: 7.3197\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 12.0166 - val_loss: 7.3940\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9919 - val_loss: 7.2409\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9864 - val_loss: 7.2578\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9789 - val_loss: 7.1333\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9682 - val_loss: 7.6808\n",
      "Epoch 20/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9502 - val_loss: 7.2616\n",
      "Epoch 21/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9585 - val_loss: 7.4432\n",
      "Epoch 22/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9656 - val_loss: 7.1142\n",
      "Epoch 23/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9820 - val_loss: 7.2610\n",
      "Epoch 24/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9635 - val_loss: 7.3025\n",
      "Epoch 25/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9740 - val_loss: 7.1299\n",
      "Epoch 26/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9694 - val_loss: 7.7850\n",
      "Epoch 27/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9649 - val_loss: 7.2232\n",
      "Epoch 28/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9712 - val_loss: 7.1565\n",
      "Epoch 29/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9703 - val_loss: 7.2295\n",
      "Epoch 30/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9555 - val_loss: 7.1985\n",
      "Epoch 31/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9583 - val_loss: 7.2079\n",
      "Epoch 32/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9555 - val_loss: 7.2363\n",
      "Epoch 33/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9760 - val_loss: 7.2783\n",
      "Epoch 34/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9762 - val_loss: 7.1968\n",
      "Epoch 35/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9825 - val_loss: 7.2264\n",
      "Epoch 36/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 11.9528 - val_loss: 7.4862\n",
      "Epoch 37/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 11.9654 - val_loss: 7.0959\n",
      "Epoch 38/100\n",
      "2443776/4800000 [==============>...............] - ETA: 26s - loss: 11.9680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a0c02fa37045>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([15], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 8.0008 - val_loss: 3.1309\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 5.4179 - val_loss: 2.9020\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 5.0405 - val_loss: 4.2036\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.7940 - val_loss: 2.6208\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.6407 - val_loss: 2.7119\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.4608 - val_loss: 2.9327\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.3300 - val_loss: 2.5436\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 4.2245 - val_loss: 2.9734\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 4.1742 - val_loss: 2.6520\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.1200 - val_loss: 2.8819\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0988 - val_loss: 2.8884\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0841 - val_loss: 2.8396\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0741 - val_loss: 2.6604\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 4.0438 - val_loss: 2.9562\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0309 - val_loss: 2.6686\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0231 - val_loss: 2.8579\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0201 - val_loss: 2.9836\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0299 - val_loss: 2.9325\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0087 - val_loss: 2.5746\n",
      "Epoch 20/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0139 - val_loss: 2.5624\n",
      "Epoch 21/100\n",
      "4800000/4800000 [==============================] - 61s 13us/sample - loss: 3.9999 - val_loss: 4.7259\n",
      "Epoch 22/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 4.0244 - val_loss: 3.0595\n",
      "Epoch 23/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 3.9924 - val_loss: 2.5325\n",
      "Epoch 24/100\n",
      "4800000/4800000 [==============================] - 62s 13us/sample - loss: 3.9811 - val_loss: 2.6233\n",
      "Epoch 25/100\n",
      "2217984/4800000 [============>.................] - ETA: 29s - loss: 3.9880"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e6938e73e367>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([500], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 13.3002 - val_loss: 4.0712\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 7.8001 - val_loss: 4.6459\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.8031 - val_loss: 3.5528\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.4332 - val_loss: 4.2553\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.2579 - val_loss: 4.0340\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.1847 - val_loss: 3.9218\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.1346 - val_loss: 3.5830\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 142s 30us/sample - loss: 6.0986 - val_loss: 3.6551\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.0579 - val_loss: 3.6091\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 6.0319 - val_loss: 3.4777\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9899 - val_loss: 3.6145\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 142s 30us/sample - loss: 5.9883 - val_loss: 3.5197\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 142s 30us/sample - loss: 5.9556 - val_loss: 3.4196\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9598 - val_loss: 3.4947\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9243 - val_loss: 3.4008\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.9189 - val_loss: 3.3627\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.8977 - val_loss: 3.3087\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.8779 - val_loss: 3.5730\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 143s 30us/sample - loss: 5.8731 - val_loss: 3.5771\n",
      "Epoch 20/100\n",
      "4611584/4800000 [===========================>..] - ETA: 5s - loss: 5.8635"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ff2059a22792>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([100, 100, 100, 100, 100], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 67s 14us/sample - loss: 202.4892 - val_loss: 13.4314\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 66s 14us/sample - loss: 115237.4813 - val_loss: 164.7734\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 66s 14us/sample - loss: 167.3936 - val_loss: 164.8833\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 66s 14us/sample - loss: 549129.0161 - val_loss: 175.0603\n",
      "Epoch 5/100\n",
      " 420864/4800000 [=>............................] - ETA: 54s - loss: 18380.3153"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-96bb44167356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    894\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m       \u001b[0munwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0munwrapped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36munwrapped\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_WeakObjectIdentityWrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0munwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([100, 100, 100, 100, 100], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  batch_normalize=False)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 12.8883 - val_loss: 3.5692\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 5.7667 - val_loss: 2.5786\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 4.7603 - val_loss: 3.1555\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 4.4252 - val_loss: 309.1072\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.2636 - val_loss: 2.2508\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.1511 - val_loss: 4436.3405\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.0706 - val_loss: 14.5775\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 159s 33us/sample - loss: 4.0452 - val_loss: 32.9513\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 158s 33us/sample - loss: 4.0056 - val_loss: 19.9872\n",
      "Epoch 10/100\n",
      "4168448/4800000 [=========================>....] - ETA: 19s - loss: 3.9490"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-8c4fa3c66a45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 7.3008 - val_loss: 2.8402\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 5.1486 - val_loss: 3.7827\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.8529 - val_loss: 4.8270\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.6608 - val_loss: 2.5731\n",
      "Epoch 5/100\n",
      "2498304/4800000 [==============>...............] - ETA: 39s - loss: 4.6195"
     ]
    }
   ],
   "source": [
    "model = get_model([5000], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 224s 47us/sample - loss: 48.8194 - val_loss: 11.4369\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 219s 46us/sample - loss: 26.1217 - val_loss: 10.8959\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 218s 45us/sample - loss: 26.0487 - val_loss: 10.8269\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 222s 46us/sample - loss: 26.0719 - val_loss: 12.0236\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 217s 45us/sample - loss: 26.0500 - val_loss: 13.3661\n",
      "Epoch 6/100\n",
      "1746688/4800000 [=========>....................] - ETA: 2:03 - loss: 26.0422"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-38916d307d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([5, 5, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 172s 36us/sample - loss: 42.9939 - val_loss: 10.0021\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 174s 36us/sample - loss: 20.1647 - val_loss: 9.8603\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 164s 34us/sample - loss: 20.0829 - val_loss: 9.4635\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 161s 34us/sample - loss: 20.0729 - val_loss: 9.8240\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 166s 35us/sample - loss: 20.0878 - val_loss: 9.8719\n",
      "Epoch 6/100\n",
      " 790784/4800000 [===>..........................] - ETA: 2:01 - loss: 20.0811"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7676d89de169>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# Callbacks batch end.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m         \u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     if (self._delta_t_batch > 0. and\n\u001b[1;32m    241\u001b[0m         delta_t_median > 0.95 * self._delta_t_batch and delta_t_median > 0.1):\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3500\u001b[0m     \"\"\"\n\u001b[1;32m   3501\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3502\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3504\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3406\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3407\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3408\u001b[0;31m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3410\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([10, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/paperspace/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/10\n",
      "4800000/4800000 [==============================] - 80s 17us/sample - loss: 25.5611 - val_loss: 7.3653\n",
      "Epoch 2/10\n",
      "4800000/4800000 [==============================] - 77s 16us/sample - loss: 12.0984 - val_loss: 7.0932\n",
      "Epoch 3/10\n",
      "4800000/4800000 [==============================] - 84s 17us/sample - loss: 12.0196 - val_loss: 7.1279\n",
      "Epoch 4/10\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 12.0069 - val_loss: 7.0612\n",
      "Epoch 5/10\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 11.9833 - val_loss: 6.9703\n",
      "Epoch 6/10\n",
      "4800000/4800000 [==============================] - 81s 17us/sample - loss: 11.9750 - val_loss: 7.1786\n",
      "Epoch 7/10\n",
      "4800000/4800000 [==============================] - 80s 17us/sample - loss: 11.9748 - val_loss: 6.9613\n",
      "Epoch 8/10\n",
      "4800000/4800000 [==============================] - 81s 17us/sample - loss: 11.9580 - val_loss: 6.9539\n",
      "Epoch 9/10\n",
      "4800000/4800000 [==============================] - 80s 17us/sample - loss: 11.9463 - val_loss: 7.0008\n",
      "Epoch 10/10\n",
      "4800000/4800000 [==============================] - 75s 16us/sample - loss: 11.9471 - val_loss: 6.9249\n"
     ]
    }
   ],
   "source": [
    "model = get_model([15], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  activation='relu')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=10,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 50.3523 - val_loss: 12.7424\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 130s 27us/sample - loss: 27.8034 - val_loss: 12.1463\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 131s 27us/sample - loss: 27.6975 - val_loss: 11.7970\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 128s 27us/sample - loss: 27.6322 - val_loss: 13.3223\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 134s 28us/sample - loss: 27.6775 - val_loss: 13.1721\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 137s 29us/sample - loss: 27.6419 - val_loss: 12.4129\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 137s 29us/sample - loss: 27.6025 - val_loss: 12.2265\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 147s 31us/sample - loss: 27.6078 - val_loss: 12.4064\n"
     ]
    }
   ],
   "source": [
    "model = get_model([5, 5, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  activation='relu')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 117s 24us/sample - loss: 42.3217 - val_loss: 8.3668\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 100s 21us/sample - loss: 18.9661 - val_loss: 8.1182\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 86s 18us/sample - loss: 18.8520 - val_loss: 7.6443\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 18.8636 - val_loss: 8.0244\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 84s 17us/sample - loss: 18.8398 - val_loss: 8.7172\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 18.8393 - val_loss: 8.2132\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 83s 17us/sample - loss: 18.8204 - val_loss: 7.3794\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 84s 17us/sample - loss: 18.8080 - val_loss: 7.7428\n"
     ]
    }
   ],
   "source": [
    "model = get_model([15, 5], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  activation='relu')\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 11.1837 - val_loss: 3.7003\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 63s 13us/sample - loss: 6.8007 - val_loss: 3.6081\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 6.0367 - val_loss: 4.1625\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 5.6892 - val_loss: 3.4377\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 63s 13us/sample - loss: 5.5148 - val_loss: 3.6943\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 5.4518 - val_loss: 3.2989\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 64s 13us/sample - loss: 5.4245 - val_loss: 3.3145\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 63s 13us/sample - loss: 5.3908 - val_loss: 3.2829\n"
     ]
    }
   ],
   "source": [
    "model = get_model([128], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/12\n",
      "4800000/4800000 [==============================] - 86s 18us/sample - loss: 21.9059 - val_loss: 4.0473\n",
      "Epoch 2/12\n",
      "4800000/4800000 [==============================] - 85s 18us/sample - loss: 8.2692 - val_loss: 3.7120\n",
      "Epoch 3/12\n",
      "4800000/4800000 [==============================] - 85s 18us/sample - loss: 8.0695 - val_loss: 3.5602\n",
      "Epoch 4/12\n",
      "4800000/4800000 [==============================] - 88s 18us/sample - loss: 7.9730 - val_loss: 4.1879\n",
      "Epoch 5/12\n",
      "4800000/4800000 [==============================] - 96s 20us/sample - loss: 7.9305 - val_loss: 3.3472\n",
      "Epoch 6/12\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 7.8957 - val_loss: 3.3317\n",
      "Epoch 7/12\n",
      "4800000/4800000 [==============================] - 96s 20us/sample - loss: 7.8690 - val_loss: 3.4243\n",
      "Epoch 8/12\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 7.8472 - val_loss: 3.8116\n",
      "Epoch 9/12\n",
      "4800000/4800000 [==============================] - 114s 24us/sample - loss: 7.8291 - val_loss: 3.9032\n",
      "Epoch 10/12\n",
      "4800000/4800000 [==============================] - 111s 23us/sample - loss: 7.8051 - val_loss: 3.2297\n",
      "Epoch 11/12\n",
      "4800000/4800000 [==============================] - 110s 23us/sample - loss: 7.7890 - val_loss: 3.8438\n",
      "Epoch 12/12\n",
      "4800000/4800000 [==============================] - 106s 22us/sample - loss: 7.7757 - val_loss: 3.2775\n"
     ]
    }
   ],
   "source": [
    "model = get_model([128, 16], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=12,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/8\n",
      "4800000/4800000 [==============================] - 136s 28us/sample - loss: 29.9069 - val_loss: 4.2152\n",
      "Epoch 2/8\n",
      "4800000/4800000 [==============================] - 136s 28us/sample - loss: 11.4651 - val_loss: 3.8083\n",
      "Epoch 3/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 11.2788 - val_loss: 4.0260\n",
      "Epoch 4/8\n",
      "4800000/4800000 [==============================] - 138s 29us/sample - loss: 11.1688 - val_loss: 4.3138\n",
      "Epoch 5/8\n",
      "4800000/4800000 [==============================] - 136s 28us/sample - loss: 11.0813 - val_loss: 4.0562\n",
      "Epoch 6/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 11.0176 - val_loss: 3.7826\n",
      "Epoch 7/8\n",
      "4800000/4800000 [==============================] - 137s 28us/sample - loss: 10.9728 - val_loss: 3.9522\n",
      "Epoch 8/8\n",
      "4800000/4800000 [==============================] - 135s 28us/sample - loss: 10.9442 - val_loss: 3.8960\n"
     ]
    }
   ],
   "source": [
    "model = get_model([128, 32, 8], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=8,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/100\n",
      "4800000/4800000 [==============================] - 108s 23us/sample - loss: 7.1860 - val_loss: 3.3847\n",
      "Epoch 2/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 5.1986 - val_loss: 3.3246\n",
      "Epoch 3/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.8692 - val_loss: 4.8711\n",
      "Epoch 4/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.7152 - val_loss: 2.5231\n",
      "Epoch 5/100\n",
      "4800000/4800000 [==============================] - 108s 23us/sample - loss: 4.5298 - val_loss: 3.2547\n",
      "Epoch 6/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.4617 - val_loss: 2.7942\n",
      "Epoch 7/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.3447 - val_loss: 2.5366\n",
      "Epoch 8/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.2427 - val_loss: 2.3994\n",
      "Epoch 9/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.1448 - val_loss: 3.3732\n",
      "Epoch 10/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 4.0818 - val_loss: 2.9512\n",
      "Epoch 11/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 4.0262 - val_loss: 2.3891\n",
      "Epoch 12/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 3.9779 - val_loss: 2.5769\n",
      "Epoch 13/100\n",
      "4800000/4800000 [==============================] - 106s 22us/sample - loss: 3.9445 - val_loss: 2.9509\n",
      "Epoch 14/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.9523 - val_loss: 2.4075\n",
      "Epoch 15/100\n",
      "4800000/4800000 [==============================] - 106s 22us/sample - loss: 3.9162 - val_loss: 2.4417\n",
      "Epoch 16/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.9470 - val_loss: 2.4907\n",
      "Epoch 17/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.9263 - val_loss: 3.5233\n",
      "Epoch 18/100\n",
      "4800000/4800000 [==============================] - 108s 22us/sample - loss: 3.8758 - val_loss: 2.4139\n",
      "Epoch 19/100\n",
      "4800000/4800000 [==============================] - 107s 22us/sample - loss: 3.8645 - val_loss: 2.8473\n",
      "Epoch 20/100\n",
      " 402944/4800000 [=>............................] - ETA: 1:29 - loss: 3.8708"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-27dcb525a5ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                     validation_data=(X_valid, y_valid))\n\u001b[0m",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = get_model([5000], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 13.0878 - val_loss: 2.9907\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 5.8280 - val_loss: 2.5856\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 4.7800 - val_loss: 2.7688\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 4.4607 - val_loss: 2.3796\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 4.3031 - val_loss: 15.3050\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.2039 - val_loss: 2.2770\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.1206 - val_loss: 8.9059\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 4.0869 - val_loss: 280505539.8805\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0325 - val_loss: 1052.1793\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9876 - val_loss: 5.5977\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.9669 - val_loss: 4.0471\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9446 - val_loss: 2.1333\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9237 - val_loss: 2.0119\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9024 - val_loss: 2.4977\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8632 - val_loss: 1.9823\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8550 - val_loss: 1.9337\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8300 - val_loss: 1.9897\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8304 - val_loss: 2.1272\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8079 - val_loss: 2.0409\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.7801 - val_loss: 2.0700\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 212s 44us/sample - loss: 12.9860 - val_loss: 3.1617\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 5.8028 - val_loss: 2.6816\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.7634 - val_loss: 2.5463\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.4010 - val_loss: 2.9659\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.2706 - val_loss: 2.1884\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.1639 - val_loss: 2.1545\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0972 - val_loss: 2.1666\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0556 - val_loss: 2.1983\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 4.0265 - val_loss: 2.8349\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9863 - val_loss: 2.4432\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9457 - val_loss: 2.1738\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.9340 - val_loss: 2.2053\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.9156 - val_loss: 2.0885\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8839 - val_loss: 2.0635\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8690 - val_loss: 8.3698\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8546 - val_loss: 2.0075\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8375 - val_loss: 2.1485\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 209s 43us/sample - loss: 3.8230 - val_loss: 2.1459\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 210s 44us/sample - loss: 3.8196 - val_loss: 2.0498\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 209s 44us/sample - loss: 3.8136 - val_loss: 2.2360\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 223s 47us/sample - loss: 12.8854 - val_loss: 3.5177\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 229s 48us/sample - loss: 5.7637 - val_loss: 3.3164\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 246s 51us/sample - loss: 4.7659 - val_loss: 29.1539\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.4171 - val_loss: 2.4747\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.2490 - val_loss: 3.2411\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.1509 - val_loss: 2.5327\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.1054 - val_loss: 3.0509\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.0573 - val_loss: 5.4738\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 4.0072 - val_loss: 2.2892\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 231s 48us/sample - loss: 3.9792 - val_loss: 2.3805\n",
      "Epoch 11/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.9524 - val_loss: 2.6415\n",
      "Epoch 12/20\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.9188 - val_loss: 2.2294\n",
      "Epoch 13/20\n",
      "4800000/4800000 [==============================] - 233s 48us/sample - loss: 3.8881 - val_loss: 1.9912\n",
      "Epoch 14/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8796 - val_loss: 2.0057\n",
      "Epoch 15/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8563 - val_loss: 1.9987\n",
      "Epoch 16/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8369 - val_loss: 2.0174\n",
      "Epoch 17/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.7997 - val_loss: 2.1469\n",
      "Epoch 18/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.7955 - val_loss: 1.9409\n",
      "Epoch 19/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.8064 - val_loss: 2.1279\n",
      "Epoch 20/20\n",
      "4800000/4800000 [==============================] - 233s 49us/sample - loss: 3.7880 - val_loss: 1.8837\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-3.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AMSE, alpha=0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_mean_squared_error_04(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true) * K.square(K.sign(y_pred - y_true) + 0.4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/20\n",
      "4800000/4800000 [==============================] - 247s 51us/sample - loss: 8.3800 - val_loss: 2.6513\n",
      "Epoch 2/20\n",
      "4800000/4800000 [==============================] - 242s 51us/sample - loss: 4.5051 - val_loss: 2.5057\n",
      "Epoch 3/20\n",
      "4800000/4800000 [==============================] - 242s 51us/sample - loss: 3.7943 - val_loss: 2.0409\n",
      "Epoch 4/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.5439 - val_loss: 1.9140\n",
      "Epoch 5/20\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.3845 - val_loss: 1.8999\n",
      "Epoch 6/20\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.3091 - val_loss: 2.4136\n",
      "Epoch 7/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.2403 - val_loss: 1.7266\n",
      "Epoch 8/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.2016 - val_loss: 1.8663\n",
      "Epoch 9/20\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.1717 - val_loss: 2.0870\n",
      "Epoch 10/20\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1603 - val_loss: 1.8342\n",
      "CPU times: user 56min 35s, sys: 4min 36s, total: 1h 1min 12s\n",
      "Wall time: 40min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=3, verbose=0, restore_best_weights=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras-1024-1024-512-128-64-v3-amse04-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 8.3634 - val_loss: 3.5793\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 253s 53us/sample - loss: 4.5414 - val_loss: 2.7090\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.8168 - val_loss: 2.3052\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.5222 - val_loss: 2.3101\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.3929 - val_loss: 1.8131\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.3102 - val_loss: 2.2506\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.2417 - val_loss: 1.8867\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.2142 - val_loss: 2.6003\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 245s 51us/sample - loss: 3.1755 - val_loss: 1.7152\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.1425 - val_loss: 1.9231\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.1303 - val_loss: 277.6915\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.1005 - val_loss: 88.0225\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0920 - val_loss: 1.7814\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0707 - val_loss: 914.4154\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0526 - val_loss: 1.8667\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0387 - val_loss: 1.9346\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 3.0233 - val_loss: 62047076.8117\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.0152 - val_loss: 1.6986\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 3.0234 - val_loss: 1.7852\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.9836 - val_loss: 1.6347\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9867 - val_loss: 1.6535\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9805 - val_loss: 1.6567\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.9640 - val_loss: 356184.7334\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9588 - val_loss: 1.6762\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9552 - val_loss: 6457714.6806\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9433 - val_loss: 15661375.7751\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9330 - val_loss: 6195131.3061\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9262 - val_loss: 5113962.6409\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9131 - val_loss: 1.5780\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.9230 - val_loss: 4999898.5668\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.9096 - val_loss: 3492335.0001\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8957 - val_loss: 137561.1607\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8920 - val_loss: 6884356.2422\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8941 - val_loss: 1475141.1350\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8860 - val_loss: 59552.7642\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8835 - val_loss: 234715.0152\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8852 - val_loss: 15694963.9812\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 236s 49us/sample - loss: 2.8684 - val_loss: 4542683.9539\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8765 - val_loss: 1629458.8849\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 235s 49us/sample - loss: 2.8732 - val_loss: 3231357.1123\n",
      "CPU times: user 3h 41min 36s, sys: 18min 32s, total: 4h 9s\n",
      "Wall time: 2h 39min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-amse04-3.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 8.3150 - val_loss: 2.4547\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 4.4960 - val_loss: 2.7192\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 3.7889 - val_loss: 2.4314\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.5379 - val_loss: 1.9856\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.3963 - val_loss: 48.4876\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.3032 - val_loss: 2.8606\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 238s 49us/sample - loss: 3.2540 - val_loss: 4.5467\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.2179 - val_loss: 4.7233\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.1747 - val_loss: 4.0300\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.1527 - val_loss: 1.8894\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 238s 49us/sample - loss: 3.1312 - val_loss: 1.8136\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 237s 49us/sample - loss: 3.1104 - val_loss: 1.8657\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0980 - val_loss: 1.7585\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0770 - val_loss: 1.7649\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 3.0519 - val_loss: 1.6816\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0295 - val_loss: 1.8498\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0239 - val_loss: 1.7714\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0147 - val_loss: 1.7429\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 3.0045 - val_loss: 1.8313\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9977 - val_loss: 1.6902\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9931 - val_loss: 1.9906\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9869 - val_loss: 1.8978\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9728 - val_loss: 1.6030\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.9637 - val_loss: 1.8370\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9568 - val_loss: 1.6377\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9515 - val_loss: 1.7680\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9436 - val_loss: 1.6250\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9243 - val_loss: 1.6446\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.9224 - val_loss: 1.5389\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.9179 - val_loss: 1.6121\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9032 - val_loss: 1.7710\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.9076 - val_loss: 1.5725\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8994 - val_loss: 1.6273\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8949 - val_loss: 1.6577\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8737 - val_loss: 1.7294\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.8766 - val_loss: 1.5923\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8839 - val_loss: 1.8764\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 239s 50us/sample - loss: 2.8782 - val_loss: 6.6154\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8624 - val_loss: 1.8187\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 238s 50us/sample - loss: 2.8611 - val_loss: 2.3418\n",
      "CPU times: user 3h 41min 46s, sys: 18min 33s, total: 4h 19s\n",
      "Wall time: 2h 38min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('keras-1024-1024-512-128-64-v3-amse04-3.h5',\n",
    "                                   custom_objects={asymmetric_mean_squared_error_04.__name__: asymmetric_mean_squared_error_04})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8913850946363677"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 8.3449 - val_loss: 3.7893\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 4.4897 - val_loss: 2.2052\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.7583 - val_loss: 2.0451\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.5055 - val_loss: 2.0100\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.3776 - val_loss: 2.0147\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.3018 - val_loss: 2.0523\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.2558 - val_loss: 1.8675\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.2037 - val_loss: 1.7872\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1923 - val_loss: 3.2376\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1583 - val_loss: 8.8307\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.1185 - val_loss: 1216.3931\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0966 - val_loss: 1.9918\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.0890 - val_loss: 110930.8774\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0621 - val_loss: 156.8690\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0546 - val_loss: 6.5130\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 244s 51us/sample - loss: 3.0455 - val_loss: 1.7364\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0286 - val_loss: 1.7845\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 3.0185 - val_loss: 1.7453\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 3.0095 - val_loss: 1.6705\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9940 - val_loss: 2.1684\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9907 - val_loss: 1.9844\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 224s 47us/sample - loss: 2.9715 - val_loss: 1.5377\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9703 - val_loss: 1.6315\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 247s 51us/sample - loss: 2.9606 - val_loss: 2.3864\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 243s 51us/sample - loss: 2.9516 - val_loss: 1.8395\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9390 - val_loss: 1.9771\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9424 - val_loss: 1.6930\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9275 - val_loss: 1.6061\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.9287 - val_loss: 1.9347\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9238 - val_loss: 1.6880\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9131 - val_loss: 1.5577\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.9100 - val_loss: 1.7984\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8974 - val_loss: 1.8434\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.8991 - val_loss: 1.8684\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8944 - val_loss: 1.8435\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8924 - val_loss: 1.5575\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8934 - val_loss: 94.0635\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 242s 50us/sample - loss: 2.8824 - val_loss: 13.4017\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.8819 - val_loss: 1.6585\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 241s 50us/sample - loss: 2.8684 - val_loss: 267093.3174\n",
      "CPU times: user 3h 40min 45s, sys: 18min 4s, total: 3h 58min 49s\n",
      "Wall time: 2h 41min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 8.3486 - val_loss: 4.7409\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 4.5064 - val_loss: 2.1276\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.7776 - val_loss: 2.2662\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.5308 - val_loss: 2.6638\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.4002 - val_loss: 1.9170\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.3178 - val_loss: 2.6013\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.2558 - val_loss: 1.7402\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 3.2282 - val_loss: 10791.7317\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 3.1876 - val_loss: 1437.1145\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.1708 - val_loss: 469.4790\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.1319 - val_loss: 139960.6894\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.1044 - val_loss: 4579060.3049\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0858 - val_loss: 5329438.3289\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.0830 - val_loss: 18408214.2301\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0594 - val_loss: 31789944.5470\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 3.0419 - val_loss: 162245988.1828\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0339 - val_loss: 88622506.1740\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 252s 53us/sample - loss: 3.0268 - val_loss: 585828.9373\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 3.0187 - val_loss: 4911885.5310\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9969 - val_loss: 58244169.3112\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9935 - val_loss: 367343743.9879\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9808 - val_loss: 364841271.1517\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9775 - val_loss: 792687609.1806\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9676 - val_loss: 6443006.5615\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9474 - val_loss: 385887654.6068\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 2.9482 - val_loss: 48253160.6182\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9462 - val_loss: 142375366.3380\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9345 - val_loss: 112080.9123\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 252s 52us/sample - loss: 2.9242 - val_loss: 1563385346.9028\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9265 - val_loss: 147921938.0516\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 251s 52us/sample - loss: 2.9264 - val_loss: 296702082.2584\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 250s 52us/sample - loss: 2.9185 - val_loss: 6566833.6883\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 258s 54us/sample - loss: 2.9017 - val_loss: 58608063.5017\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 253s 53us/sample - loss: 2.9080 - val_loss: 206219016.5040\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 252s 53us/sample - loss: 2.8881 - val_loss: 45578219.3036\n",
      "Epoch 36/40\n",
      "1070336/4800000 [=====>........................] - ETA: 3:01 - loss: 2.8753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-amse04-5.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2,\n",
    "                  loss=asymmetric_mean_squared_error_04)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model: keras-1024-1024-512-128-64-v3-1.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 270s 56us/sample - loss: 13.0070 - val_loss: 3.3146\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 5.7860 - val_loss: 4.5887\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.7713 - val_loss: 2.5165\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.4423 - val_loss: 2.5784\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 258s 54us/sample - loss: 4.3127 - val_loss: 2.2928\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.1951 - val_loss: 12.5933\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.1247 - val_loss: 2.5574\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0545 - val_loss: 2.9832\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0182 - val_loss: 2.3749\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.9742 - val_loss: 163.8348\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9571 - val_loss: 2.2052\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 257s 54us/sample - loss: 3.9274 - val_loss: 2.1400\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9101 - val_loss: 2.1041\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8916 - val_loss: 2.1763\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 257s 53us/sample - loss: 3.8878 - val_loss: 2.3184\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8442 - val_loss: 2.0434\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8313 - val_loss: 2.1751\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8212 - val_loss: 2.3354\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.8035 - val_loss: 1.9400\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7991 - val_loss: 1.9030\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7657 - val_loss: 1.9228\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7759 - val_loss: 2.4104\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7576 - val_loss: 1.9955\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7567 - val_loss: 2.0136\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7399 - val_loss: 1.9386\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7368 - val_loss: 1.9805\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 257s 53us/sample - loss: 3.7158 - val_loss: 2.1287\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.7139 - val_loss: 1.8709\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.7070 - val_loss: 2.1099\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.7209 - val_loss: 1.8675\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6997 - val_loss: 2.2452\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6951 - val_loss: 2.4613\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6976 - val_loss: 1.8948\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6837 - val_loss: 1.9712\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6727 - val_loss: 2.0730\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 257s 53us/sample - loss: 3.6778 - val_loss: 1.9845\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6669 - val_loss: 2.0188\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6514 - val_loss: 2.4476\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6546 - val_loss: 1.9911\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.6467 - val_loss: 2.3256\n",
      "CPU times: user 3h 53min 1s, sys: 19min 43s, total: 4h 12min 44s\n",
      "Wall time: 2h 50min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('keras-1024-1024-512-128-64-v3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8675305894823022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 271s 56us/sample - loss: 13.0124 - val_loss: 3.6991\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 5.7911 - val_loss: 3.7446\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.7769 - val_loss: 2.5686\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.4388 - val_loss: 2.3743\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.2847 - val_loss: 2.4757\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.1626 - val_loss: 2.1205\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 4.1088 - val_loss: 2.4977\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0771 - val_loss: 2.1508\n",
      "Epoch 9/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 4.0196 - val_loss: 2.1536\n",
      "Epoch 10/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.9921 - val_loss: 2.4548\n",
      "Epoch 11/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9656 - val_loss: 2.1206\n",
      "Epoch 12/40\n",
      "4800000/4800000 [==============================] - 256s 53us/sample - loss: 3.9379 - val_loss: 2.2943\n",
      "Epoch 13/40\n",
      "4800000/4800000 [==============================] - 265s 55us/sample - loss: 3.9026 - val_loss: 2.1921\n",
      "Epoch 14/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.8971 - val_loss: 2.1851\n",
      "Epoch 15/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.8661 - val_loss: 1.9834\n",
      "Epoch 16/40\n",
      "4800000/4800000 [==============================] - 268s 56us/sample - loss: 3.8501 - val_loss: 2.0140\n",
      "Epoch 17/40\n",
      "4800000/4800000 [==============================] - 278s 58us/sample - loss: 3.8396 - val_loss: 2.1410\n",
      "Epoch 18/40\n",
      "4800000/4800000 [==============================] - 271s 57us/sample - loss: 3.8229 - val_loss: 2.1005\n",
      "Epoch 19/40\n",
      "4800000/4800000 [==============================] - 326s 68us/sample - loss: 3.8207 - val_loss: 1.9484\n",
      "Epoch 20/40\n",
      "4800000/4800000 [==============================] - 328s 68us/sample - loss: 3.8010 - val_loss: 1.9993\n",
      "Epoch 21/40\n",
      "4800000/4800000 [==============================] - 328s 68us/sample - loss: 3.7982 - val_loss: 2.0993\n",
      "Epoch 22/40\n",
      "4800000/4800000 [==============================] - 328s 68us/sample - loss: 3.7767 - val_loss: 1.9732\n",
      "Epoch 23/40\n",
      "4800000/4800000 [==============================] - 327s 68us/sample - loss: 3.7673 - val_loss: 2.0655\n",
      "Epoch 24/40\n",
      "4800000/4800000 [==============================] - 320s 67us/sample - loss: 3.7518 - val_loss: 2.2873\n",
      "Epoch 25/40\n",
      "4800000/4800000 [==============================] - 334s 70us/sample - loss: 3.7488 - val_loss: 1.8986\n",
      "Epoch 26/40\n",
      "4800000/4800000 [==============================] - 331s 69us/sample - loss: 3.7412 - val_loss: 1.9701\n",
      "Epoch 27/40\n",
      "4800000/4800000 [==============================] - 333s 69us/sample - loss: 3.7428 - val_loss: 1.9944\n",
      "Epoch 28/40\n",
      "4800000/4800000 [==============================] - 331s 69us/sample - loss: 3.7434 - val_loss: 1.9937\n",
      "Epoch 29/40\n",
      "4800000/4800000 [==============================] - 330s 69us/sample - loss: 3.7106 - val_loss: 1.9217\n",
      "Epoch 30/40\n",
      "4800000/4800000 [==============================] - 330s 69us/sample - loss: 3.7182 - val_loss: 2.3163\n",
      "Epoch 31/40\n",
      "4800000/4800000 [==============================] - 333s 69us/sample - loss: 3.7043 - val_loss: 2.1778\n",
      "Epoch 32/40\n",
      "4800000/4800000 [==============================] - 332s 69us/sample - loss: 3.7031 - val_loss: 2.0672\n",
      "Epoch 33/40\n",
      "4800000/4800000 [==============================] - 259s 54us/sample - loss: 3.6970 - val_loss: 2.0881\n",
      "Epoch 34/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6829 - val_loss: 1.9642\n",
      "Epoch 35/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6939 - val_loss: 2.2310\n",
      "Epoch 36/40\n",
      "4800000/4800000 [==============================] - 254s 53us/sample - loss: 3.6750 - val_loss: 2.3429\n",
      "Epoch 37/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6682 - val_loss: 2.4458\n",
      "Epoch 38/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6646 - val_loss: 76118.5880\n",
      "Epoch 39/40\n",
      "4800000/4800000 [==============================] - 254s 53us/sample - loss: 3.6570 - val_loss: 434056.1523\n",
      "Epoch 40/40\n",
      "4800000/4800000 [==============================] - 255s 53us/sample - loss: 3.6692 - val_loss: 1038544.6152\n",
      "CPU times: user 4h 16min 51s, sys: 18min 49s, total: 4h 35min 41s\n",
      "Wall time: 3h 8min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-2.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 277s 58us/sample - loss: 13.0028 - val_loss: 3.3558\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 5.8031 - val_loss: 2.6444\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.7973 - val_loss: 2.5292\n",
      "Epoch 4/40\n",
      "4800000/4800000 [==============================] - 261s 54us/sample - loss: 4.4799 - val_loss: 2.4988\n",
      "Epoch 5/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.3033 - val_loss: 808.3861\n",
      "Epoch 6/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.1995 - val_loss: 4.0642\n",
      "Epoch 7/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.1261 - val_loss: 220.3238\n",
      "Epoch 8/40\n",
      "4800000/4800000 [==============================] - 260s 54us/sample - loss: 4.0780 - val_loss: 47311.7997\n",
      "Epoch 9/40\n",
      "4798976/4800000 [============================>.] - ETA: 0s - loss: 4.0697"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m           \u001b[0mvalidation_in_fit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m           \u001b[0mprepared_feed_values_from_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m           steps_name='validation_steps')\n\u001b[0m\u001b[1;32m    441\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mval_results\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    483\u001b[0m   \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_input_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mas_default\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3867\u001b[0m       \u001b[0mA\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0musing\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3868\u001b[0m     \"\"\"\n\u001b[0;32m-> 3869\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_default_graph_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_controller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3871\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36mhelper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_GeneratorContextManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mhelper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, args, kwds)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# Issue 19330: ensure context manager instances have good docstrings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-3.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/40\n",
      "4800000/4800000 [==============================] - 281s 59us/sample - loss: 13.0054 - val_loss: 3.2030\n",
      "Epoch 2/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 5.7812 - val_loss: 2.7538\n",
      "Epoch 3/40\n",
      "4800000/4800000 [==============================] - 264s 55us/sample - loss: 4.7179 - val_loss: 12.6293\n",
      "Epoch 4/40\n",
      "2884608/4800000 [=================>............] - ETA: 1:36 - loss: 4.4559"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-1024-1024-512-128-64-v3-4.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([1024, 1024, 512, 128, 64], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=40,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4800000 samples, validate on 1200000 samples\n",
      "Epoch 1/30\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 7.2334 - val_loss: 3.3782\n",
      "Epoch 2/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 5.1244 - val_loss: 3.0224\n",
      "Epoch 3/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.8281 - val_loss: 2.7550\n",
      "Epoch 4/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.6901 - val_loss: 4.2794\n",
      "Epoch 5/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.5216 - val_loss: 4.8058\n",
      "Epoch 6/30\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 4.4135 - val_loss: 3.0279\n",
      "Epoch 7/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.2783 - val_loss: 2.5983\n",
      "Epoch 8/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.1820 - val_loss: 2.3754\n",
      "Epoch 9/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 4.0460 - val_loss: 2.6025\n",
      "Epoch 10/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 4.0142 - val_loss: 3.8428\n",
      "Epoch 11/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.9608 - val_loss: 2.3549\n",
      "Epoch 12/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.9020 - val_loss: 2.9286\n",
      "Epoch 13/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 3.8773 - val_loss: 2.5941\n",
      "Epoch 14/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8752 - val_loss: 2.3389\n",
      "Epoch 15/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8479 - val_loss: 2.8763\n",
      "Epoch 16/30\n",
      "4800000/4800000 [==============================] - 92s 19us/sample - loss: 3.8644 - val_loss: 2.3547\n",
      "Epoch 17/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8100 - val_loss: 2.6379\n",
      "Epoch 18/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8173 - val_loss: 2.4167\n",
      "Epoch 19/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8073 - val_loss: 2.6643\n",
      "Epoch 20/30\n",
      "4800000/4800000 [==============================] - 94s 20us/sample - loss: 3.8172 - val_loss: 2.9329\n",
      "Epoch 21/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8072 - val_loss: 2.4161\n",
      "Epoch 22/30\n",
      "4800000/4800000 [==============================] - 93s 19us/sample - loss: 3.8245 - val_loss: 2.3694\n",
      "Epoch 23/30\n",
      "1272064/4800000 [======>.......................] - ETA: 1:01 - loss: 3.7915"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3439\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m     \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    894\u001b[0m   \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m   \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.miniconda3/envs/fifteen-puzzle-gpu/lib/python3.7/site-packages/tensorflow_core/python/util/object_identity.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0munwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint('keras-2752-v3-1.h5', \n",
    "                                                      save_best_only=True)\n",
    "\n",
    "model = get_model([2752], \n",
    "                  learning_rate=0.01, \n",
    "                  dropout_ratio=0.2)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=256,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('../../../data/neural-networks/keras-2752-v3-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.338850735974764"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y_pred = model.predict(X_valid)\n",
    "mean_squared_error(y_pred, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
